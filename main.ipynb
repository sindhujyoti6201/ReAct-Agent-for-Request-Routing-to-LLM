{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhujyoti6201/ai-assignment-1/blob/main/assignments/assignment-4/04-assignment-4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install requests beautifulsoup4 pydantic openai unified-planning\n",
        "!pip3 install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8Fd5MiO8lQr",
        "outputId": "ece75dd9-688a-4c4f-e39b-fee0d684d031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: unified-planning in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from unified-planning) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unified-planning) (3.4.2)\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from unified-planning) (1.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning) (1.15.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning) (10.7.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.168.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDDL\n",
        "The OpenRouter domain is characterized by:\n",
        "\n",
        "Multiple LLMs\n",
        "Multiple LLM providers.\n",
        "Each LLM has capabilities (e.g., coding, multilingual, safe for kids, long context).\n",
        "Each request has functional requirements (e.g., supports code, must be open-source, etc.)\n",
        "Each account has a upper limit on the number of dollars it can spend for prompt tokens and completion tokens.\n",
        "Each LLM has a limit on the number of tokens it can process as part of its context.\n",
        "Each provider has a cost associated with each LLM expressed in $/m (dollars/million) tokens.\n",
        "This is not an exhaustive list and therefore you need to embark into an ontology engineering exercise to identify the relevant entities and relationships that will be used to build the PDDL domain and problem files. You can use a simple RAG Agent to help you with this task. You need to produce a structured output where the dictionary keys are the required PDDL specification keywords as shown below. For example the key types will contain all PDDL domain types.\n",
        "\n",
        "PDDL Domain\n",
        "Use a free LLM that will search over the OpenRouter documentation pages and extract all relevant types.\n",
        "\n",
        "Write a PDDL domain file that includes the following:\n",
        "\n",
        "A set of types that represent the entities in the OpenRouter domain.\n",
        "A set of predicates that represent the relationships between the entities.\n",
        "A set of actions that represent the operations that can be performed in the OpenRouter domain. Each action should have preconditions and effects that are relevant to the OpenRouter domain.\n",
        "PDDL Problem\n",
        "Write a PDDL problem file that includes the following: * A set of objects that represent the specific instances of the types defined in the domain file. * A set of init predicates that represent the initial state of the OpenRouter domain. This should include the available LLMs, providers, and their capabilities. * A set of goal predicates that represent the desired state of the OpenRouter domain. This should include the successful routing of requests to the appropriate LLMs based on their capabilities and costs.\n",
        "\n",
        "Solve the PDDL problem using an appropriate PDDL solver provided by the Unified Planning library and use its ability to read and write PDDL files.\n",
        "\n",
        "Note\n",
        "You are free to use relevant VSCode plugins to help you with the PDDL domain and problem statement as well as solver calls, however, the agent must be in its entirety implemented in Python."
      ],
      "metadata": {
        "id": "O6qqKlbvoqv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRACTION OF DATA FROM THE OPENROUTER APIs"
      ],
      "metadata": {
        "id": "lv4JX_7K0FuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def fetch_and_save_models_data():\n",
        "    url = \"https://openrouter.ai/api/v1/models\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['data']\n",
        "        with open(\"models_data.json\", \"w\") as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "        print(\"models_data.json saved.\")\n",
        "    else:\n",
        "        raise Exception(f\"Failed to fetch models. Status code: {response.status_code}\")\n",
        "\n",
        "fetch_and_save_models_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeiTPewawq8J",
        "outputId": "d3eed1e9-0d5b-4c70-ad93-ef3d681b35ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models_data.json saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MINIMIZING AND EXTRACTING KEY/REQUIRED FEATURES"
      ],
      "metadata": {
        "id": "OKRxojQK0Ndw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os, re\n",
        "\n",
        "def summarize_model_data(input_file=\"models_data.json\", output_file=\"models_summary.json\"):\n",
        "    with open(input_file, \"r\") as f:\n",
        "        models = json.load(f)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert data extraction assistant trained to analyze complex model metadata from OpenRouter.\n",
        "Your task is to extract only the most relevant attributes for routing large language model (LLM) requests.\n",
        "\n",
        "The input is a JSON array of detailed model descriptions. From each model object, extract and return the following fields in a clean JSON array:\n",
        "\n",
        "- model id (string): The unique model identifier (e.g., \"meta-llama/llama-guard-4-12b\")\n",
        "- model name (string): Human-readable name\n",
        "- context_length (integer): The maximum context tokens allowed\n",
        "- input_modalities (list of strings): Accepted input types (e.g., text, image)\n",
        "- output_modalities (list of strings): Output types generated by the model\n",
        "- capabilities (list of strings or inferred tags): Such as coding, multilingual, safety, reasoning, etc.\n",
        "- pricing (object): Including prompt and completion cost in $/token (extract only those two fields)\n",
        "- supported_parameters (list of strings): The list of tunable parameters this model supports\n",
        "\n",
        "Be sure to only extract what's required, and maintain a compact, flat structure in the output JSON.\n",
        "\n",
        "Here is the input JSON data:\n",
        "{json.dumps(models[:10])}\n",
        "\n",
        "Please just output the JSON array. Do not include any additional text or explanation.\n",
        "\"\"\"\n",
        "\n",
        "    client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key='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')\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-3.3-70b-instruct:free\",\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt},\n",
        "                  {\"role\": \"user\", \"content\": \"You are a data summarizer for model routing.\"}]\n",
        "    )\n",
        "\n",
        "    if response and response.choices and response.choices[0].message:\n",
        "        raw_output = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Extract all text between the first triple backticks block (if exists)\n",
        "        try:\n",
        "            match = re.search(r\"```(?:json)?\\\\s*(.*?)```\", raw_output, re.DOTALL)\n",
        "            json_str = match.group(1).strip() if match else raw_output\n",
        "\n",
        "            parsed_json = json.loads(json_str)\n",
        "            with open(output_file, \"w\") as f:\n",
        "                json.dump(parsed_json, f, indent=2)\n",
        "            print(\"models_summary.json saved.\")\n",
        "        except Exception as e:\n",
        "            print(\"Failed to parse JSON from model response.\")\n",
        "            print(\"Raw output:\", raw_output)\n",
        "            print(\"Error:\", str(e))\n",
        "    else:\n",
        "        print(\"No valid response received from the model.\")\n",
        "        print(\"Raw response:\", response)\n",
        "\n",
        "summarize_model_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhEsaJRNxvtI",
        "outputId": "5ffc559d-2426-4e86-ccf7-393835b3b909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models_summary.json saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENERATION OF PDDL FILES"
      ],
      "metadata": {
        "id": "Rq83rM050Wt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOMAIN.PDDL USING OPENROUTER MAVERICK MODEL"
      ],
      "metadata": {
        "id": "hv0UbtX50dj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_domain_pddl(summary_path=\"models_summary.json\"):\n",
        "    with open(summary_path, \"r\") as f:\n",
        "        summary = f.read()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert in PDDL (Planning Domain Definition Language) and Pyperplan. You are given a task to create a PDDL domain file for routing AI model requests through OpenRouter. The domain should be compatible with Pyperplan.\n",
        "Using the following model metadata:\n",
        "{summary}\n",
        "\n",
        "Generate a complete and syntactically correct PDDL domain file in Pyperplan compatible format for routing AI model requests through OpenRouter. Your output should include:\n",
        "\n",
        "1. (:types): Define the types: llm, provider, capability, request, account. etc...\n",
        "2. (:predicates): Define logical predicates such as:\n",
        "   - (has-capability ?m - llm ?c - capability)\n",
        "   - (belongs-to ?m - llm ?p - provider)\n",
        "   - (has-cost ?m - llm ?d - cost)\n",
        "   - (has-token-limit ?m - llm ?t - tokenlimit)\n",
        "   - (meets-requirement ?r - request ?c - capability)\n",
        "   - (can-handle ?m - llm ?r - request)\n",
        "   and other logical predicates as needed.\n",
        "3. (:action route-request):\n",
        "   - Parameters: (?r - request ?m - llm)\n",
        "   - Preconditions: The llm has required capability, cost, and context token limits to satisfy request\n",
        "   - Effects: The request is routed to the llm\n",
        "   and other necessary actions and effects.\n",
        "\n",
        "4. FOR EVERY variable(?l) define its type like ?l - llm -- FOLLOW THESE IMPORTANT\n",
        "5. There should be following prdeicates in the domain file as a mandatory:\n",
        "    (fits-request ?l - llm ?r - request)\n",
        "    (meets-requirement ?r - request ?c - capability)\n",
        "    (not-processed ?r - request)\n",
        "    (processed ?r - request)\n",
        "    (routed ?r - request ?l - llm)\n",
        "6. There should be the following actions in the domain file as a mandatory:\n",
        "    (:action route-request\n",
        "    :parameters (?r - request ?l - llm)\n",
        "    :precondition (and\n",
        "      (not-processed ?r)\n",
        "      (fits-request ?l ?r)\n",
        "    )\n",
        "    :effect (and\n",
        "      (not (not-processed ?r))\n",
        "      (processed ?r)\n",
        "      (routed ?r ?l)\n",
        "    )\n",
        "  )\n",
        "7. ONLY USE THOSE OBJECTS, ACTIONS AND PREDICATES THAT ARE DEFINED IN THE objects.\n",
        "\n",
        "RULES:\n",
        "Rules for generating STRIPS-compatible PDDL:\n",
        "\n",
        "1. All PDDL files must follow valid structure: domain files require :types, :predicates, and :action definitions; problem files require :domain, :objects, :init, and :goal blocks.\n",
        "2. Only define types in :types, and use them in :parameters and :objects — do NOT specify types inside predicate calls.\n",
        "3. Every predicate used in :init, :precondition, :effect, or :goal must be declared in :predicates.\n",
        "4. Inside :parameters, define variable types like (?r - request ?l - llm), but inside expressions like (has-capability ?l ?c), do NOT repeat types.\n",
        "5. STRIPS does not support arithmetic or relational operators like <=, >=, <, >, =. Do not use expressions like (<= ?x ?y) or (+ ?a ?b). Instead, precompute and encode relationships symbolically using named predicates (e.g., (fits-context-length llm1 req1)).\n",
        "6. Do not use :functions or numeric fluents. STRIPS only allows Boolean predicates.\n",
        "7. Every variable in :parameters must be used somewhere in the :precondition or :effect of the action.\n",
        "8. Every object or constant referenced in :init or :goal must be listed in the :objects section of the problem file.\n",
        "9. Avoid existential or universal quantifiers (exists, forall) — these are not supported in basic STRIPS planners.\n",
        "10. To check conditions like token limits, cost, or context length, encode them symbolically as precomputed predicates in :init (e.g., (fits-request llm req)).\n",
        "11. Effects can only add or delete atomic predicates — no nested expressions or arithmetic.\n",
        "12. Use clear naming conventions for objects, types, and predicates to avoid name collisions and parsing issues.\n",
        "\n",
        "\n",
        "Other naming RULES:\n",
        "Naming Rules for Valid PDDL:\n",
        "1. Do not use hyphens (`-`) in the names of objects, constants, types, or predicates. Hyphens are reserved for type declarations in PDDL and will break parsing if used elsewhere.\n",
        "2. Use underscores (`_`) instead of hyphens for compound names. For example, use `tool_use` instead of `tool-use`.\n",
        "3. Object names must be unique within their scope and should not conflict across different types (e.g., avoid using the same name for both an inputmodality and outputmodality).\n",
        "4. All names must begin with a lowercase letter and may contain only lowercase letters, digits, and underscores.\n",
        "5. Avoid names that resemble numbers (e.g., `n0-0000025`) unless clearly distinguishable from numeric literals. Use formats like `n0000025` or `n_25` instead.\n",
        "6. Do not enclose names in quotes.\n",
        "7. Ensure that every name used in `:init`, `:goal`, `:precondition`, or `:effect` is declared under `:objects` in the problem file or as a parameter in an action.\n",
        "\n",
        "\n",
        "Sample domain file:\n",
        "(define (domain openrouter-routing)\n",
        "  (:requirements :typing)\n",
        "\n",
        "  (:types\n",
        "    llm provider capability request account number\n",
        "  )\n",
        "\n",
        "  (:predicates\n",
        "    (has-capability ?l - llm ?c - capability)\n",
        "    (provided-by ?l - llm ?p - provider)\n",
        "    (cost-prompt ?l - llm ?n - number)\n",
        "    (cost-completion ?l - llm ?n - number)\n",
        "    (context-length ?l - llm ?n - number)\n",
        "    (request-length ?r - request ?n - number)\n",
        "    (within-budget ?a - account ?n - number)\n",
        "    (fits-request ?l - llm ?r - request)\n",
        "    (meets-requirement ?r - request ?c - capability)\n",
        "    (not-processed ?r - request)\n",
        "    (processed ?r - request)\n",
        "    (routed ?r - request ?l - llm)\n",
        "  )\n",
        "\n",
        "  (:action route-request\n",
        "    :parameters (?r - request ?l - llm)\n",
        "    :precondition (and\n",
        "      (not-processed ?r)\n",
        "      (fits-request ?l ?r)\n",
        "    )\n",
        "    :effect (and\n",
        "      (not (not-processed ?r))\n",
        "      (processed ?r)\n",
        "      (routed ?r ?l)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\n",
        "\n",
        "ANOTHER SAMPLE DOMAIN FILE:\n",
        "(define (domain openrouter-routing)\n",
        "  (:requirements :strips :typing)\n",
        "\n",
        "  (:types\n",
        "    llm provider capability request account tokenlimit cost number inputmodality outputmodality parameter\n",
        "  )\n",
        "\n",
        "  (:predicates\n",
        "    (has-capability ?l - llm ?c - capability)\n",
        "    (provided-by ?l - llm ?p - provider)\n",
        "    (has-cost-prompt ?l - llm ?n - number)\n",
        "    (has-cost-completion ?l - llm ?n - number)\n",
        "    (has-token-limit ?l - llm ?t - tokenlimit)\n",
        "    (request-token-length ?r - request ?n - number)\n",
        "    (request-input-modality ?r - request ?i - inputmodality)\n",
        "    (request-output-modality ?r - request ?o - outputmodality)\n",
        "    (request-parameter ?r - request ?p - parameter)\n",
        "    (llm-input-modality ?l - llm ?i - inputmodality)\n",
        "    (llm-output-modality ?l - llm ?o - outputmodality)\n",
        "    (llm-supported-parameter ?l - llm ?p - parameter)\n",
        "    (within-budget ?a - account ?n - number)\n",
        "    (meets-requirement ?r - request ?c - capability)\n",
        "    (fits-request ?l - llm ?r - request)\n",
        "    (not-processed ?r - request)\n",
        "    (processed ?r - request)\n",
        "    (routed ?r - request ?l - llm)\n",
        "  )\n",
        "\n",
        "  (:action route-request\n",
        "    :parameters (?r - request ?l - llm)\n",
        "    :precondition (and\n",
        "      (not-processed ?r)\n",
        "      (fits-request ?l ?r)\n",
        "    )\n",
        "    :effect (and\n",
        "      (not (not-processed ?r))\n",
        "      (processed ?r)\n",
        "      (routed ?r ?l)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\n",
        "TRY TO KEEP THE DOMAIN FILE AS SIMILAR AS POSSIBLE TO THE EXAMPLE.\n",
        "\n",
        "This is a sample domain file. You can use it as a reference to create your own domain file based on the provided model metadata.OUTPUT ONLY THE DOMAIN FILE IN PDDL FORMAT. NO ADDITIONAL TEXT OR EXPLANATION. NO CODE BLOCKS LIKE ```lisp```.\n",
        "\"\"\"\n",
        "\n",
        "    client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key='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')\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-4-maverick:free\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": \"You are a PDDL generation assistant. Your task is to generate a valid domain.pddl file for use with the ENHSP planner. Use structured types and logical predicates to represent an AI model routing system.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    pddl_code = response.choices[0].message.content.strip()\n",
        "    with open(\"domain.pddl\", \"w\") as f:\n",
        "        f.write(pddl_code)\n",
        "    print(\"domain.pddl saved.\")\n",
        "\n",
        "\n",
        "generate_domain_pddl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFikyVCfzi4c",
        "outputId": "202cd03d-cb64-4eb0-c234-05d3c55d64ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "domain.pddl saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROBLEM.PDDL USING OPENROUTER MAVERICK MODEL"
      ],
      "metadata": {
        "id": "nGkX9Ybf0g2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_problem_pddl(summary_path=\"models_summary.json\", query_request = \"I want to route one request req1 to a multilingual and coding-capable request for a free user, other request req2 to safe-for-kids\", comment=\"\"):\n",
        "    with open(summary_path, \"r\") as f:\n",
        "        summary = f.read()\n",
        "\n",
        "    with open(\"domain.pddl\", \"r\") as f:\n",
        "        domain = f.read()\n",
        "\n",
        "    print(domain)\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert in PDDL (Planning Domain Definition Language) and Pyperplan. You are given a task to create a PDDL problem file for routing AI model requests through OpenRouter. The problem should be compatible with Pyperplan.\n",
        "Using the following model metadata:\n",
        "{summary}\n",
        "for the domain {domain}. Try to fix the error mention in the comment = {comment}\n",
        "\n",
        "This problem should contain the all the necessary objects, initial conditions, and goals to route requests to the appropriate LLMs based on their capabilities and requirements for the query request = {query_request}.\n",
        "\n",
        "GENERATE A PROBLEM.PDDL FILE IN PYPPERPLAN COMPATIBLE FORMAT USING {domain} and {query_request} such that there exists a plan.\n",
        "\n",
        "Before proceeding to creating the problem file, please do the following:\n",
        "1. Extract all the requests from the {query_request} and create unique request objects for each. The {query_request} should contain a requests with their requirements in a comma separated format.\n",
        "2. Create unique capability objects for each capability mentioned in the {query_request}.\n",
        "3. Create unique LLM objects for each LLM mentioned in the {query_request} and assign them to the appropriate provider.\n",
        "The problem should be structured as follows:\n",
        "\n",
        "1. Each requiring a unique combination of capabilities like 'coding', 'multilingual', or 'safe-for-kids'.\n",
        "2. Each request should:\n",
        "   - Be declared as an object of type `request`\n",
        "   - Include its requirements using (meets-requirement ?r - request ?c - capability)\n",
        "   - Have an initial status of (not-processed ?r)\n",
        "3. THE INIT SECTION IS ALWAYS FILLED IN ACCORDANCE WITH THE FOLLWOING RULES:\n",
        "Rules for Filling the :init Section in PDDL:\n",
        "\n",
        "1. Only include ground (fully instantiated) predicates — i.e., use concrete object names, no variables.\n",
        "2. Ensure that each predicate in :init exactly matches a predicate declared in the domain = {domain}, in both name and argument count.\n",
        "3. The types of each object used must match the argument types defined for that predicate in the domain.\n",
        "4. All objects referenced in :init must first be declared in the :objects section with their correct types, as specified in the domain.\n",
        "5. Do not use hyphens in object names — use underscores instead (e.g., use `safe_for_kids` not `safe-for-kids`).\n",
        "6. Only use Boolean predicates (e.g., `(has-capability llm1 multilingual)`), and avoid any numeric expressions, functions, or comparison operators like `+`, `=`, `<=`, etc.\n",
        "7. If a predicate expects an object of type `number`, then the object (e.g., `n0`) must be declared as `- number` in the :objects section — same for all custom types like `modality`, `parameter`, etc.\n",
        "8. Do not duplicate facts — ensure each fact is unique in :init.\n",
        "9. If derived predicates like `(fits-request ?l ?r)` or `(meets-requirement ?r ?c)` are required and not computed via actions, include them explicitly in :init.\n",
        "10. Follow the exact type names, object names, and predicate formats defined in the domain file. Inconsistent usage will cause parsing errors.\n",
        "\n",
        "Example of valid :init usage:\n",
        "(:init\n",
        "  (has-capability qwen_qwen3_0_6b_free multilingual)\n",
        "  (provided-by qwen_qwen3_0_6b_free openrouter)\n",
        "  (has-cost-prompt qwen_qwen3_0_6b_free n0)\n",
        "  (has-token-limit qwen_qwen3_0_6b_free tokenlimit_32000)\n",
        "  (llm-input-modality qwen_qwen3_0_6b_free text_input)\n",
        "  (llm-output-modality qwen_qwen3_0_6b_free text_output)\n",
        "  (request-input-modality req1 text_input)\n",
        "  (request-output-modality req1 text_output)\n",
        "  (not-processed req1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "3. Include a set of LLMs (up to 5) and their capabilities, costs, and context limits in the init section.\n",
        "4. Include a goal section that requires all requests to be routed (i.e., they are no longer not-processed).\n",
        "5. Use object declarations for types llm, capability, request, provider, and account.\n",
        "6. Don't use any floating points, numbers, etc .Evrything should be text.Donot use . or the decimal in pddl. Wherever you see a decimal, replace it with a dash (-). For exaample 0.5 should be replaced with 0-5, qwen3.0.6b becomes qwen3-0-6b.\n",
        "7. Goals should be route requests or processed requests. like processed req1. Don't Decide by yourself which llm to route to.\n",
        "8. ONLY USE THOSE OBJECTS, ACTIONS AND PREDICATES THAT ARE DEFINED IN THE {domain}.\n",
        "9. VERY IMPORTANT - The Goals should always be in this FORMAT.\n",
        "(:goal\n",
        "  (and\n",
        "    (processed req1)\n",
        "    (processed req2)\n",
        "    (processed req3)\n",
        "    (processed req4)..\n",
        "  )\n",
        ")\n",
        "\n",
        "\n",
        "Few CAUTIONS VERY IMPORTANT FOR THE PDDL FILE USING PYPPERPLAN:\n",
        "- Do not use the following constructs in the PDDL file:\n",
        "1. Numeric fluents and expressions like (<, >, +, -, *, /)\n",
        "2. Conditional effects like (exists, forall, imply, leq)\n",
        "3. Donot use . or the decimal in pddl. Wherever you see a decimal, replace it with a dash (-). For exaample 0.5 should be replaced with 0-5, qwen3.0.6b becomes qwen3-0-6b\n",
        "4. JUST output the domain file in PDDL format. No additional text or explanations. Nor should you use any code blocks like ```lisp or ```.\n",
        "5. DONOT USE BUILT IN FUNCTIONS LIKE forall, imply, or, max-number in the PDDL file. These don't support Pyperplan.\n",
        "6. DON't DEFINE SAME NAME IN THE OBJECTS- like the following:\n",
        "text image - inputmodality\n",
        "    text - outputmodality.\n",
        "\n",
        "    This should be :\n",
        "text-input image - inputmodality\n",
        "text-output - outputmodality\n",
        "7. Other naming RULES:\n",
        "Naming Rules for Valid PDDL:\n",
        "1. Do not use hyphens (`-`) in the names of objects, constants, types, or predicates. Hyphens are reserved for type declarations in PDDL and will break parsing if used elsewhere.\n",
        "2. Use underscores (`_`) instead of hyphens for compound names. For example, use `tool_use` instead of `tool-use`.\n",
        "3. Object names must be unique within their scope and should not conflict across different types (e.g., avoid using the same name for both an inputmodality and outputmodality).\n",
        "4. All names must begin with a lowercase letter and may contain only lowercase letters, digits, and underscores.\n",
        "5. Avoid names that resemble numbers (e.g., `n0-0000025`) unless clearly distinguishable from numeric literals. Use formats like `n0000025` or `n_25` instead.\n",
        "6. Do not enclose names in quotes.\n",
        "7. Ensure that every name used in `:init`, `:goal`, `:precondition`, or `:effect` is declared under `:objects` in the problem file or as a parameter in an action.\n",
        "\n",
        "\n",
        "Sample problem file:\n",
        "(define (problem route-llm-request)\n",
        "  (:domain openrouter-routing)\n",
        "\n",
        "  (:objects\n",
        "    qwen3-0-6b qwen3-1-7b - llm\n",
        "    p1 - provider\n",
        "    cap1 cap2 - capability\n",
        "    req1 req2 - request\n",
        "    acc1 - account\n",
        "    n0 n1 n2 n3 n4 - number\n",
        "  )\n",
        "\n",
        "  (:init\n",
        "    (has-capability qwen3-0-6b cap1)\n",
        "    (has-capability qwen3-1-7b cap2)\n",
        "    (provided-by qwen3-0-6b p1)\n",
        "    (cost-prompt qwen3-0-6b n1)\n",
        "    (cost-completion qwen3-0-6b n2)\n",
        "    (context-length qwen3-0-6b n3)\n",
        "    (request-length req1 n1)\n",
        "    (within-budget acc1 n4)\n",
        "    (meets-requirement req1 cap1)\n",
        "    (not-processed req1)\n",
        "    (fits-request qwen3-0-6b req1)\n",
        "  )\n",
        "\n",
        "  (:goal\n",
        "    (and\n",
        "      (processed req1)\n",
        "      (processed req2)\n",
        "      (processed req3)\n",
        "      (processed req4)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\n",
        "There should always be some fits-requests in the init section.\n",
        "Example:\n",
        "(fits-request qwen_qwen3_0_6b_free req1)\n",
        "(fits-request deepseek_deepseek_prover_v2_free req2)\n",
        "\n",
        "Eaxmple 2:\n",
        "(define (problem route-llm-request)\n",
        "  (:domain openrouter-routing)\n",
        "\n",
        "  (:objects\n",
        "    qwen_qwen3_30b_a3b_free meta_llama_llama_guard_4_12b - llm\n",
        "    openrouter - provider\n",
        "    multilingual coding content_safety - capability\n",
        "    req1 req2 - request\n",
        "    acc1 - account\n",
        "    n0 n1 - number\n",
        "    tokenlimit_40960 tokenlimit_163840 - tokenlimit\n",
        "    text_input image_input - inputmodality\n",
        "    text_output - outputmodality\n",
        "    max_tokens temperature - parameter\n",
        "  )\n",
        "\n",
        "  (:init\n",
        "    (has-capability qwen_qwen3_30b_a3b_free multilingual)\n",
        "    (has-capability qwen_qwen3_30b_a3b_free coding)\n",
        "    (has-capability meta_llama_llama_guard_4_12b content_safety)\n",
        "    (provided-by qwen_qwen3_30b_a3b_free openrouter)\n",
        "    (provided-by meta_llama_llama_guard_4_12b openrouter)\n",
        "    (has-cost-prompt qwen_qwen3_30b_a3b_free n0)\n",
        "    (has-cost-completion qwen_qwen3_30b_a3b_free n0)\n",
        "    (has-cost-prompt meta_llama_llama_guard_4_12b n1)\n",
        "    (has-cost-completion meta_llama_llama_guard_4_12b n1)\n",
        "    (has-token-limit qwen_qwen3_30b_a3b_free tokenlimit_40960)\n",
        "    (has-token-limit meta_llama_llama_guard_4_12b tokenlimit_163840)\n",
        "    (llm-input-modality qwen_qwen3_30b_a3b_free text_input)\n",
        "    (llm-output-modality qwen_qwen3_30b_a3b_free text_output)\n",
        "    (llm-input-modality meta_llama_llama_guard_4_12b image_input)\n",
        "    (llm-input-modality meta_llama_llama_guard_4_12b text_input)\n",
        "    (llm-output-modality meta_llama_llama_guard_4_12b text_output)\n",
        "    (llm-supported-parameter qwen_qwen3_30b_a3b_free max_tokens)\n",
        "    (llm-supported-parameter qwen_qwen3_30b_a3b_free temperature)\n",
        "    (llm-supported-parameter meta_llama_llama_guard_4_12b max_tokens)\n",
        "    (llm-supported-parameter meta_llama_llama_guard_4_12b temperature)\n",
        "    (request-input-modality req1 text_input)\n",
        "    (request-output-modality req1 text_output)\n",
        "    (request-input-modality req2 text_input)\n",
        "    (request-output-modality req2 text_output)\n",
        "    (request-input-modality req2 image_input)\n",
        "    (meets-requirement req1 multilingual)\n",
        "    (meets-requirement req1 coding)\n",
        "    (meets-requirement req2 content_safety)\n",
        "    (not-processed req1)\n",
        "    (not-processed req2)\n",
        "    (within-budget acc1 n0)\n",
        "    (fits-request qwen_qwen3_30b_a3b_free req1)\n",
        "    (fits-request meta_llama_llama_guard_4_12b req2)\n",
        "  )\n",
        "\n",
        "  (:goal\n",
        "    (and\n",
        "      (processed req1)\n",
        "      (processed req2)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\n",
        "Example 3:\n",
        "(define (problem route-llm-request)\n",
        "  (:domain openrouter-routing)\n",
        "\n",
        "  (:objects\n",
        "    qwen_qwen3_0_6b_free qwen_qwen3_1_7b_free qwen_qwen3_4b_free qwen_qwen3_30b_a3b_free deepseek_deepseek_prover_v2_free meta_llama_llama_guard_4_12b - llm\n",
        "    openrouter - provider\n",
        "    multilingual coding content_safety reasoning - capability\n",
        "    req1 req2 - request\n",
        "    acc1 - account\n",
        "    n0 n1 - number\n",
        "    tokenlimit_32000 tokenlimit_128000 tokenlimit_40960 tokenlimit_163840 - tokenlimit\n",
        "    text_input image_input - inputmodality\n",
        "    text_output - outputmodality\n",
        "    max_tokens temperature - parameter\n",
        "  )\n",
        "\n",
        "  (:init\n",
        "    (has-capability qwen_qwen3_0_6b_free multilingual)\n",
        "    (has-capability qwen_qwen3_0_6b_free reasoning)\n",
        "    (has-capability qwen_qwen3_1_7b_free multilingual)\n",
        "    (has-capability qwen_qwen3_1_7b_free reasoning)\n",
        "    (has-capability qwen_qwen3_4b_free reasoning)\n",
        "    (has-capability qwen_qwen3_30b_a3b_free multilingual)\n",
        "    (has-capability qwen_qwen3_30b_a3b_free coding)\n",
        "    (has-capability deepseek_deepseek_prover_v2_free reasoning)\n",
        "    (has-capability meta_llama_llama_guard_4_12b content_safety)\n",
        "\n",
        "    (provided-by qwen_qwen3_0_6b_free openrouter)\n",
        "    (provided-by qwen_qwen3_1_7b_free openrouter)\n",
        "    (provided-by qwen_qwen3_4b_free openrouter)\n",
        "    (provided-by qwen_qwen3_30b_a3b_free openrouter)\n",
        "    (provided-by deepseek_deepseek_prover_v2_free openrouter)\n",
        "    (provided-by meta_llama_llama_guard_4_12b openrouter)\n",
        "\n",
        "    (has-cost-prompt qwen_qwen3_0_6b_free n0)\n",
        "    (has-cost-completion qwen_qwen3_0_6b_free n0)\n",
        "    (has-cost-prompt qwen_qwen3_1_7b_free n0)\n",
        "    (has-cost-completion qwen_qwen3_1_7b_free n0)\n",
        "    (has-cost-prompt qwen_qwen3_4b_free n0)\n",
        "    (has-cost-completion qwen_qwen3_4b_free n0)\n",
        "    (has-cost-prompt qwen_qwen3_30b_a3b_free n0)\n",
        "    (has-cost-completion qwen_qwen3_30b_a3b_free n0)\n",
        "    (has-cost-prompt deepseek_deepseek_prover_v2_free n0)\n",
        "    (has-cost-completion deepseek_deepseek_prover_v2_free n0)\n",
        "    (has-cost-prompt meta_llama_llama_guard_4_12b n1)\n",
        "    (has-cost-completion meta_llama_llama_guard_4_12b n1)\n",
        "\n",
        "    (has-token-limit qwen_qwen3_0_6b_free tokenlimit_32000)\n",
        "    (has-token-limit qwen_qwen3_1_7b_free tokenlimit_32000)\n",
        "    (has-token-limit qwen_qwen3_4b_free tokenlimit_128000)\n",
        "    (has-token-limit qwen_qwen3_30b_a3b_free tokenlimit_40960)\n",
        "    (has-token-limit deepseek_deepseek_prover_v2_free tokenlimit_163840)\n",
        "    (has-token-limit meta_llama_llama_guard_4_12b tokenlimit_163840)\n",
        "\n",
        "    (llm-input-modality qwen_qwen3_0_6b_free text_input)\n",
        "    (llm-output-modality qwen_qwen3_0_6b_free text_output)\n",
        "    (llm-input-modality qwen_qwen3_1_7b_free text_input)\n",
        "    (llm-output-modality qwen_qwen3_1_7b_free text_output)\n",
        "    (llm-input-modality qwen_qwen3_4b_free text_input)\n",
        "    (llm-output-modality qwen_qwen3_4b_free text_output)\n",
        "    (llm-input-modality qwen_qwen3_30b_a3b_free text_input)\n",
        "    (llm-output-modality qwen_qwen3_30b_a3b_free text_output)\n",
        "    (llm-input-modality deepseek_deepseek_prover_v2_free text_input)\n",
        "    (llm-output-modality deepseek_deepseek_prover_v2_free text_output)\n",
        "    (llm-input-modality meta_llama_llama_guard_4_12b text_input)\n",
        "    (llm-input-modality meta_llama_llama_guard_4_12b image_input)\n",
        "    (llm-output-modality meta_llama_llama_guard_4_12b text_output)\n",
        "\n",
        "    (llm-supported-parameter qwen_qwen3_0_6b_free max_tokens)\n",
        "    (llm-supported-parameter qwen_qwen3_0_6b_free temperature)\n",
        "    (llm-supported-parameter qwen_qwen3_1_7b_free max_tokens)\n",
        "    (llm-supported-parameter qwen_qwen3_1_7b_free temperature)\n",
        "    (llm-supported-parameter qwen_qwen3_4b_free max_tokens)\n",
        "    (llm-supported-parameter qwen_qwen3_4b_free temperature)\n",
        "    (llm-supported-parameter qwen_qwen3_30b_a3b_free max_tokens)\n",
        "    (llm-supported-parameter qwen_qwen3_30b_a3b_free temperature)\n",
        "    (llm-supported-parameter deepseek_deepseek_prover_v2_free max_tokens)\n",
        "    (llm-supported-parameter deepseek_deepseek_prover_v2_free temperature)\n",
        "    (llm-supported-parameter meta_llama_llama_guard_4_12b max_tokens)\n",
        "    (llm-supported-parameter meta_llama_llama_guard_4_12b temperature)\n",
        "\n",
        "    (request-input-modality req1 text_input)\n",
        "    (request-output-modality req1 text_output)\n",
        "    (request-input-modality req2 text_input)\n",
        "    (request-input-modality req2 image_input)\n",
        "    (request-output-modality req2 text_output)\n",
        "\n",
        "    (meets-requirement req1 multilingual)\n",
        "    (meets-requirement req1 coding)\n",
        "    (meets-requirement req2 content_safety)\n",
        "\n",
        "    (not-processed req1)\n",
        "    (not-processed req2)\n",
        "\n",
        "    (within-budget acc1 n0)\n",
        "    (fits-request qwen_qwen3_30b_a3b_free req1)\n",
        "    (fits-request meta_llama_llama_guard_4_12b req2)\n",
        "  )\n",
        "\n",
        "  (:goal\n",
        "    (and\n",
        "      (processed req1)\n",
        "      (processed req2)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\n",
        "Try to fill for all the predicates mentioned in the {domain} in the init section.\n",
        "\n",
        "This is a sample problem file. You can use it as a reference to create your own domain file based on the provided model metadata.\n",
        "Make sure to include all the necessary predicates and actions that are relevant to the routing of AI model requests through OpenRouter. The domain file should be complete and ready for use with Pyperplan.\n",
        "Please don't include any additional text or explanation in the problem file. Nor should you use any code blocks like ```lisp or ```.\n",
        "\n",
        "Use consistent, lowercase, underscore-separated names for all PDDL objects, starting with a letter and avoiding malformed fragments (e.g., use qwen_qwen3_4b_free instead of q_3_4b_free), strictly matching the types and format declared in the domain.\n",
        "\"\"\"\n",
        "\n",
        "    client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key='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')\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-4-maverick:free\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": \"You are a PDDL generation assistant. Your task is to generate a valid problem.pddl file compatible with Pyperplan based on provided domain constraints and object definitions. remove ```lisp from the start of the file and ``` from the end of the file.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    pddl_code = response.choices[0].message.content.strip()\n",
        "    with open(\"problem.pddl\", \"w\") as f:\n",
        "        f.write(pddl_code)\n",
        "    print(\"problem.pddl saved.\")\n",
        "\n",
        "generate_problem_pddl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bSMzflICX2X",
        "outputId": "5eaa4791-71cf-4a1a-c4fb-6a49fcfb05d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(define (domain openrouter-routing)\n",
            "  (:requirements :strips :typing)\n",
            "\n",
            "  (:types\n",
            "    llm provider capability request account tokenlimit cost number inputmodality outputmodality parameter\n",
            "  )\n",
            "\n",
            "  (:predicates\n",
            "    (has_capability ?l - llm ?c - capability)\n",
            "    (belongs_to ?l - llm ?p - provider)\n",
            "    (has_cost_prompt ?l - llm ?n - number)\n",
            "    (has_cost_completion ?l - llm ?n - number)\n",
            "    (has_token_limit ?l - llm ?t - tokenlimit)\n",
            "    (request_token_length ?r - request ?n - number)\n",
            "    (request_input_modality ?r - request ?i - inputmodality)\n",
            "    (request_output_modality ?r - request ?o - outputmodality)\n",
            "    (request_parameter ?r - request ?p - parameter)\n",
            "    (llm_input_modality ?l - llm ?i - inputmodality)\n",
            "    (llm_output_modality ?l - llm ?o - outputmodality)\n",
            "    (llm_supported_parameter ?l - llm ?p - parameter)\n",
            "    (within_budget ?a - account ?n - number)\n",
            "    (meets_requirement ?r - request ?c - capability)\n",
            "    (fits_request ?l - llm ?r - request)\n",
            "    (not_processed ?r - request)\n",
            "    (processed ?r - request)\n",
            "    (routed ?r - request ?l - llm)\n",
            "    (can_handle ?l - llm ?r - request)\n",
            "  )\n",
            "\n",
            "  (:action route_request\n",
            "    :parameters (?r - request ?l - llm)\n",
            "    :precondition (and\n",
            "      (not_processed ?r)\n",
            "      (fits_request ?l ?r)\n",
            "    )\n",
            "    :effect (and\n",
            "      (not (not_processed ?r))\n",
            "      (processed ?r)\n",
            "      (routed ?r ?l)\n",
            "    )\n",
            "  )\n",
            "\n",
            "  (:action check_capability\n",
            "    :parameters (?l - llm ?r - request ?c - capability)\n",
            "    :precondition (and\n",
            "      (has_capability ?l ?c)\n",
            "      (meets_requirement ?r ?c)\n",
            "    )\n",
            "    :effect (can_handle ?l ?r)\n",
            "  )\n",
            "\n",
            "  (:action check_modality\n",
            "    :parameters (?l - llm ?r - request ?i - inputmodality ?o - outputmodality)\n",
            "    :precondition (and\n",
            "      (request_input_modality ?r ?i)\n",
            "      (request_output_modality ?r ?o)\n",
            "      (llm_input_modality ?l ?i)\n",
            "      (llm_output_modality ?l ?o)\n",
            "    )\n",
            "    :effect (can_handle ?l ?r)\n",
            "  )\n",
            "\n",
            "  (:action check_parameter\n",
            "    :parameters (?l - llm ?r - request ?p - parameter)\n",
            "    :precondition (and\n",
            "      (request_parameter ?r ?p)\n",
            "      (llm_supported_parameter ?l ?p)\n",
            "    )\n",
            "    :effect (can_handle ?l ?r)\n",
            "  )\n",
            "\n",
            "  (:action check_token_limit\n",
            "    :parameters (?l - llm ?r - request ?n - number ?t - tokenlimit)\n",
            "    :precondition (and\n",
            "      (has_token_limit ?l ?t)\n",
            "      (request_token_length ?r ?n)\n",
            "      ; Assuming a predicate (less_than ?n ?t) is defined elsewhere or precomputed\n",
            "      ; For STRIPS compliance, this should be precomputed and represented as a predicate\n",
            "      ; (fits_token_limit ?l ?r)\n",
            "      ; For simplicity, we'll directly use (fits_request ?l ?r) which should be precomputed\n",
            "    )\n",
            "    :effect (and)\n",
            "  )\n",
            ")\n",
            "problem.pddl saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLVERS"
      ],
      "metadata": {
        "id": "7PXOrJEV0rb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unified-planning[planners]\n",
        "!pip install unified-planning[enhsp]\n",
        "!pip install unified-planning[pyperplan]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BpmlLtyFzkg",
        "outputId": "57b34adf-4783-4ab6-e6d3-6559afc7228a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unified-planning[planners] in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "\u001b[33mWARNING: unified-planning 1.2.0 does not provide the extra 'planners'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from unified-planning[planners]) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unified-planning[planners]) (3.4.2)\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from unified-planning[planners]) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[planners]) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[planners]) (1.15.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[planners]) (4.13.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[planners]) (10.7.0)\n",
            "Requirement already satisfied: unified-planning[enhsp] in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from unified-planning[enhsp]) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unified-planning[enhsp]) (3.4.2)\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from unified-planning[enhsp]) (1.2.1)\n",
            "Requirement already satisfied: up-enhsp~=0.0.27 in /usr/local/lib/python3.11/dist-packages (from unified-planning[enhsp]) (0.0.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[enhsp]) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[enhsp]) (1.15.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[enhsp]) (4.13.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[enhsp]) (10.7.0)\n",
            "Requirement already satisfied: unified-planning[pyperplan] in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from unified-planning[pyperplan]) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unified-planning[pyperplan]) (3.4.2)\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.11/dist-packages (from unified-planning[pyperplan]) (1.2.1)\n",
            "Requirement already satisfied: up-pyperplan~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from unified-planning[pyperplan]) (1.1.0)\n",
            "Requirement already satisfied: pyperplan==2.1 in /usr/local/lib/python3.11/dist-packages (from up-pyperplan~=1.1.0->unified-planning[pyperplan]) (2.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from pyperplan==2.1->up-pyperplan~=1.1.0->unified-planning[pyperplan]) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[pyperplan]) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[pyperplan]) (1.15.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[pyperplan]) (4.13.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from ConfigSpace->unified-planning[pyperplan]) (10.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unified_planning.io import PDDLReader\n",
        "from unified_planning.shortcuts import OneshotPlanner\n",
        "def solve_pddl():\n",
        "    reader = PDDLReader()\n",
        "    problem = reader.parse_problem('/content/domain.pddl', '/content/problem.pddl')\n",
        "\n",
        "    try:\n",
        "      print(f\"Using to Pyperplan solver\")\n",
        "      with OneshotPlanner(name='pyperplan') as planner:\n",
        "          result = planner.solve(problem)\n",
        "          print(f\"Planner used: {planner.name}\")\n",
        "          print(f\"Result Status: {result.status}\")\n",
        "\n",
        "      if result.plan:\n",
        "          res = \"Solved PDDL. The plan is:\\n\"\n",
        "          print(\"Plan Found:\")\n",
        "          for action in result.plan.actions:\n",
        "              res += str(action) + \"\\n\"\n",
        "          return res\n",
        "      else:\n",
        "          print(\"No plan found.\")\n",
        "          return \"No plan found.\"\n",
        "    except Exception as e:\n",
        "      return str(e)\n",
        "\n",
        "\n",
        "\n",
        "print(\"==============================DOMAIN.PDDL=============================\")\n",
        "with open(\"domain.pddl\", \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(\"==============================PROBLEM.PDDL=============================\")\n",
        "with open(\"problem.pddl\", \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(\"==============================PLAN=============================\")\n",
        "solve_pddl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lkFOZLEA-dAD",
        "outputId": "84797020-9370-4be9-bdb3-0a0345ee2578",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================DOMAIN.PDDL=============================\n",
            "(define (domain openrouter-routing)\n",
            "  (:requirements :strips :typing)\n",
            "\n",
            "  (:types\n",
            "    llm provider capability request account tokenlimit cost number inputmodality outputmodality parameter\n",
            "  )\n",
            "\n",
            "  (:predicates\n",
            "    (has-capability ?l - llm ?c - capability)\n",
            "    (provided-by ?l - llm ?p - provider)\n",
            "    (has-cost-prompt ?l - llm ?n - number)\n",
            "    (has-cost-completion ?l - llm ?n - number)\n",
            "    (has-token-limit ?l - llm ?t - tokenlimit)\n",
            "    (request-token-length ?r - request ?n - number)\n",
            "    (request-input-modality ?r - request ?i - inputmodality)\n",
            "    (request-output-modality ?r - request ?o - outputmodality)\n",
            "    (request-parameter ?r - request ?p - parameter)\n",
            "    (llm-input-modality ?l - llm ?i - inputmodality)\n",
            "    (llm-output-modality ?l - llm ?o - outputmodality)\n",
            "    (llm-supported-parameter ?l - llm ?p - parameter)\n",
            "    (within-budget ?a - account ?n - number)\n",
            "    (meets-requirement ?r - request ?c - capability)\n",
            "    (fits-request ?l - llm ?r - request)\n",
            "    (not-processed ?r - request)\n",
            "    (processed ?r - request)\n",
            "    (routed ?r - request ?l - llm)\n",
            "  )\n",
            "\n",
            "  (:action route-request\n",
            "    :parameters (?r - request ?l - llm)\n",
            "    :precondition (and\n",
            "      (not-processed ?r)\n",
            "      (fits-request ?l ?r)\n",
            "    )\n",
            "    :effect (and\n",
            "      (not (not-processed ?r))\n",
            "      (processed ?r)\n",
            "      (routed ?r ?l)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "==============================PROBLEM.PDDL=============================\n",
            "(define (problem route-llm-request)\n",
            "  (:domain openrouter-routing)\n",
            "\n",
            "  (:objects\n",
            "    qwen_qwen3_0_6b_free qwen_qwen3_1_7b_free qwen_qwen3_4b_free opengvlab_internvl3_14b_free deepseek_deepseek_prover_v2_free - llm\n",
            "    openrouter - provider\n",
            "    multilingual coding safe_for_kids content_safety multimodal - capability\n",
            "    req1 req2 - request\n",
            "    free_user - account\n",
            "    n0 n1 - number\n",
            "    tokenlimit_32000 tokenlimit_128000 - tokenlimit\n",
            "    text_input image_input - inputmodality\n",
            "    text_output - outputmodality\n",
            "    max_tokens temperature top_p - parameter\n",
            "  )\n",
            "\n",
            "  (:init\n",
            "    ; LLMs and their capabilities\n",
            "    (has-capability qwen_qwen3_0_6b_free multilingual)\n",
            "    (has-capability qwen_qwen3_0_6b_free coding)\n",
            "    (has-capability qwen_qwen3_1_7b_free multilingual)\n",
            "    (has-capability opengvlab_internvl3_14b_free multimodal)\n",
            "    (has-capability deepseek_deepseek_prover_v2_free content_safety)\n",
            "    (provided-by qwen_qwen3_0_6b_free openrouter)\n",
            "    (provided-by qwen_qwen3_1_7b_free openrouter)\n",
            "    (provided-by qwen_qwen3_4b_free openrouter)\n",
            "    (provided-by opengvlab_internvl3_14b_free openrouter)\n",
            "    (provided-by deepseek_deepseek_prover_v2_free openrouter)\n",
            "\n",
            "    ; LLM costs and token limits\n",
            "    (has-cost-prompt qwen_qwen3_0_6b_free n0)\n",
            "    (has-cost-completion qwen_qwen3_0_6b_free n0)\n",
            "    (has-token-limit qwen_qwen3_0_6b_free tokenlimit_32000)\n",
            "    (has-cost-prompt qwen_qwen3_1_7b_free n0)\n",
            "    (has-cost-completion qwen_qwen3_1_7b_free n0)\n",
            "    (has-token-limit qwen_qwen3_1_7b_free tokenlimit_32000)\n",
            "    (has-token-limit qwen_qwen3_4b_free tokenlimit_128000)\n",
            "    (has-cost-prompt qwen_qwen3_4b_free n0)\n",
            "    (has-cost-completion qwen_qwen3_4b_free n0)\n",
            "    (has-cost-prompt opengvlab_internvl3_14b_free n0)\n",
            "    (has-cost-completion opengvlab_internvl3_14b_free n0)\n",
            "    (has-token-limit opengvlab_internvl3_14b_free tokenlimit_32000)\n",
            "    (has-cost-prompt deepseek_deepseek_prover_v2_free n0)\n",
            "    (has-cost-completion deepseek_deepseek_prover_v2_free n0)\n",
            "\n",
            "    ; LLM input and output modalities\n",
            "    (llm-input-modality qwen_qwen3_0_6b_free text_input)\n",
            "    (llm-output-modality qwen_qwen3_0_6b_free text_output)\n",
            "    (llm-input-modality qwen_qwen3_1_7b_free text_input)\n",
            "    (llm-output-modality qwen_qwen3_1_7b_free text_output)\n",
            "    (llm-input-modality qwen_qwen3_4b_free text_input)\n",
            "    (llm-output-modality qwen_qwen3_4b_free text_output)\n",
            "    (llm-input-modality opengvlab_internvl3_14b_free image_input)\n",
            "    (llm-input-modality opengvlab_internvl3_14b_free text_input)\n",
            "    (llm-output-modality opengvlab_internvl3_14b_free text_output)\n",
            "    (llm-input-modality deepseek_deepseek_prover_v2_free text_input)\n",
            "    (llm-output-modality deepseek_deepseek_prover_v2_free text_output)\n",
            "\n",
            "    ; LLM supported parameters\n",
            "    (llm-supported-parameter qwen_qwen3_0_6b_free max_tokens)\n",
            "    (llm-supported-parameter qwen_qwen3_0_6b_free temperature)\n",
            "    (llm-supported-parameter qwen_qwen3_1_7b_free max_tokens)\n",
            "    (llm-supported-parameter opengvlab_internvl3_14b_free max_tokens)\n",
            "    (llm-supported-parameter deepseek_deepseek_prover_v2_free max_tokens)\n",
            "\n",
            "    ; Request definitions\n",
            "    (request-input-modality req1 text_input)\n",
            "    (request-output-modality req1 text_output)\n",
            "    (request-input-modality req2 text_input)\n",
            "    (request-output-modality req2 text_output)\n",
            "\n",
            "    ; Request requirements\n",
            "    (meets-requirement req1 multilingual)\n",
            "    (meets-requirement req1 coding)\n",
            "    (meets-requirement req2 safe_for_kids)\n",
            "\n",
            "    ; Initial state of requests\n",
            "    (not-processed req1)\n",
            "    (not-processed req2)\n",
            "\n",
            "    ; Account budget\n",
            "    (within-budget free_user n1)\n",
            "\n",
            "    ; Fits-request predicate\n",
            "    (fits-request qwen_qwen3_0_6b_free req1)\n",
            "    (fits-request qwen_qwen3_1_7b_free req1)\n",
            "    (fits-request deepseek_deepseek_prover_v2_free req2)\n",
            "  )\n",
            "\n",
            "  (:goal\n",
            "    (and\n",
            "      (processed req1)\n",
            "      (processed req2)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "==============================PLAN=============================\n",
            "Using to Pyperplan solver\n",
            "\u001b[96m\u001b[1mNOTE: To disable printing of planning engine credits, add this line to your code: `up.shortcuts.get_environment().credits_stream = None`\n",
            "\u001b[0m\u001b[96m  *** Credits ***\n",
            "\u001b[0m\u001b[96m  * In operation mode `OneshotPlanner` at line 9 of `<ipython-input-4-9680c8bb7370>`, \u001b[0m\u001b[96myou are using the following planning engine:\n",
            "\u001b[0m\u001b[96m  * Engine name: pyperplan\n",
            "  * Developers:  Albert-Ludwigs-Universität Freiburg (Yusra Alkhazraji, Matthias Frorath, Markus Grützner, Malte Helmert, Thomas Liebetraut, Robert Mattmüller, Manuela Ortlieb, Jendrik Seipp, Tobias Springenberg, Philip Stahl, Jan Wülfing)\n",
            "\u001b[0m\u001b[96m  * Description: \u001b[0m\u001b[96mPyperplan is a lightweight STRIPS planner written in Python.\u001b[0m\u001b[96m\n",
            "\u001b[0m\u001b[96m\n",
            "\u001b[0mPlanner used: Pyperplan\n",
            "Result Status: PlanGenerationResultStatus.SOLVED_SATISFICING\n",
            "Plan Found:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Solved PDDL. The plan is:\\nroute-request(req2, deepseek_deepseek_prover_v2_free)\\nroute-request(req1, qwen_qwen3_1_7b_free)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReAct Agent Implementation\n",
        "The previous step showcased a feedforward apprach where LLMs where used to help you craft the PDDL domain and problem files. Here we are going to incorporate it into a ReAct agent that will be able to reason and act in a step-by-step manner, often reacting depending on the feedback we receive from the environment.\n",
        "\n",
        "You must use the Model Context Protocol (MCP) servers to structure the tool calling component of the agent. Tools are external to the agent APIs that can help it achieve its goal. For example, the calls to the Unified Planning library may be considered a tool that the agent can call when it needs to.\n",
        "\n",
        "Your agent should be able to interact with an environment that simulates the OpenRouter API and therefore provides the necessary information for the agent to make decisions such as deviating from its default routing policy. Alternatively, you may use the OpenRouter API directly if you prefer but limit yourselves to free models and include additional information that will necessitate routing policy change such as dynamic pricing.\n"
      ],
      "metadata": {
        "id": "2gHP8z_ICKFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_for_pddl_files_generation(query, comment):\n",
        "    try:\n",
        "        fetch_and_save_models_data()\n",
        "        summarize_model_data()\n",
        "        generate_domain_pddl()\n",
        "        generate_problem_pddl(query, comment)\n",
        "\n",
        "        return \"Pipeline completed successfully.\"\n",
        "    except Exception as e:\n",
        "        return str(e)\n"
      ],
      "metadata": {
        "id": "Ojy4NJdHl3qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "id": "zLCZ-b5wrECt",
        "outputId": "20a3b03b-8ea6-497a-9eb5-b74051e778f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.23.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Setup client\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "\n",
        "# === ReAct Agent ===\n",
        "class ReActAgent:\n",
        "    def __init__(self, client, system=\"\"):\n",
        "        self.client = client\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "        self.initial_query = \"\"\n",
        "        self.last_generate_argument = \"\"\n",
        "\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
        "\n",
        "        self.tools = {\n",
        "            \"generate_pddl\": run_pipeline_for_pddl_files_generation,\n",
        "            \"solve_pddl\": solve_pddl\n",
        "        }\n",
        "\n",
        "    def run(self, query: str, max_steps: int = 10):\n",
        "        print(f\"Running ReAct agent for query: '{query}'\")\n",
        "        self.initial_query = query\n",
        "        next_prompt = query\n",
        "\n",
        "        for i in range(max_steps):\n",
        "            self.messages.append({\"role\": \"user\", \"content\": next_prompt})\n",
        "            result = self._call_model()\n",
        "            print(\"-------- MODEL RESPONSE --------\")\n",
        "            print(result)\n",
        "            print(\"--------------------------------\")\n",
        "\n",
        "            if \"Answer:\" in result:\n",
        "                return result\n",
        "\n",
        "            if \"Action:\" in result and \"PAUSE\" in result:\n",
        "                action_match = re.search(r\"Action:\\s*(\\w+):\", result)\n",
        "                if not action_match:\n",
        "                    next_prompt = \"Observation: Invalid action\"\n",
        "                    print(f\"<<< {next_prompt}\")\n",
        "                    continue\n",
        "\n",
        "                action = action_match.group(1).strip()\n",
        "                argument = \"\"\n",
        "\n",
        "                if action == \"generate_pddl\":\n",
        "                    arg_match = re.search(r\"Action:\\s*generate_pddl:\\s*(.*)\", result)\n",
        "                    if arg_match:\n",
        "                        argument = arg_match.group(1).strip()\n",
        "                        self.last_generate_argument = argument\n",
        "                elif action == \"solve_pddl\":\n",
        "                    argument = \"\"\n",
        "\n",
        "                print(f\"Action: {action}, Argument: {argument}\")\n",
        "\n",
        "                try:\n",
        "                    if action == \"generate_pddl\":\n",
        "                        result_tool = self.tools[action](argument)\n",
        "                    elif action == \"solve_pddl\":\n",
        "                        try:\n",
        "                            result_tool = self.tools[action]()\n",
        "                        except Exception as e:\n",
        "                            # Retry generate_pddl with error context\n",
        "                            retry_comment = f\"[RETRY due to error: {str(e)}]\"\n",
        "                            print(\"Solve failed. Regenerating PDDL with error context...\")\n",
        "                            self.tools[\"generate_pddl\"](self.last_generate_argument, retry_comment)\n",
        "                            print(\"Retrying solve...\")\n",
        "                            result_tool = self.tools[\"solve_pddl\"]()\n",
        "                    else:\n",
        "                        result_tool = \"Tool not found\"\n",
        "\n",
        "                except Exception as e:\n",
        "                    result_tool = f\"Tool {action} failed with error: {e}\"\n",
        "\n",
        "                next_prompt = f\"Observation: {result_tool}\"\n",
        "                print(f\">>> {next_prompt}\")\n",
        "                continue\n",
        "\n",
        "            break\n",
        "\n",
        "    def _call_model(self):\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=\"llama3-70b-8192\",\n",
        "            messages=self.messages,\n",
        "            temperature=0\n",
        "        )\n",
        "        content = completion.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "        return content\n",
        "\n",
        "\n",
        "# === ReAct Prompt ===\n",
        "\n",
        "react_system_prompt = \"\"\"\n",
        "You are a ReAct agent operating in a loop of: Thought → Action → PAUSE → Observation.\n",
        "At the end, output a final Answer.\n",
        "\n",
        "Use:\n",
        "- Thought: Describe what you're thinking.\n",
        "- Action: Call an available tool with: tool_name: input\n",
        "- PAUSE: Always follows an action.\n",
        "- Observation: Will be returned as a user message.\n",
        "\n",
        "Available tools:\n",
        "- generate_pddl: <task_description>\n",
        "- solve_pddl: <leave blank>\n",
        "\n",
        "The following is only for example purposes. DONOT USE IT IN PRODUCTION.\n",
        "Example or sample:\n",
        "\n",
        "Question: I want to solve a planning problem for OpenRouter LLM routing.\n",
        "\n",
        "Thought: I need to generate the PDDL files that define the domain and problem.\n",
        "Action: generate_pddl: OpenRouter LLM routing problem\n",
        "PAUSE\n",
        "\n",
        "Observation: PDDL files generated for: OpenRouter LLM routing problem\n",
        "\n",
        "Thought: Now I should solve this PDDL problem using a planning tool.\n",
        "Action: solve_pddl:\n",
        "PAUSE\n",
        "\n",
        "Observation: Solved PDDL problem. Plan: (select-llm qwen3-14b user-request)\n",
        "\n",
        "Answer: The request was routed successfully using the plan: (select-llm qwen3-14b user-request)\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "# === Run the Agent ===\n",
        "\n",
        "agent = ReActAgent(client, system=react_system_prompt)\n",
        "agent.run(\"I want to route a multilingual and coding-capable request for a free user.\")"
      ],
      "metadata": {
        "id": "I2lsWFJDrVRn",
        "outputId": "8bc59396-544b-45b4-9e3c-c633020f8685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running ReAct agent for query: 'I want to route a multilingual and coding-capable request for a free user.'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: I need to generate the PDDL files that define the domain and problem for this request.\n",
            "\n",
            "Action: generate_pddl: multilingual and coding-capable request for a free user\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: generate_pddl, Argument: multilingual and coding-capable request for a free user\n",
            ">>> Observation: Tool generate_pddl failed with error: run_pipeline_for_pddl_files_generation() missing 1 required positional argument: 'comment'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: It seems like the generate_pddl tool requires more information, specifically a comment about the request.\n",
            "\n",
            "Action: generate_pddl: multilingual and coding-capable request for a free user, comment: route a free user request that supports multiple languages and coding capabilities\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: generate_pddl, Argument: multilingual and coding-capable request for a free user, comment: route a free user request that supports multiple languages and coding capabilities\n",
            ">>> Observation: Tool generate_pddl failed with error: run_pipeline_for_pddl_files_generation() missing 1 required positional argument: 'comment'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: I still didn't provide the required comment argument. Let me try again with a more detailed comment.\n",
            "\n",
            "Action: generate_pddl: multilingual and coding-capable request for a free user, comment: route a free user request that supports multiple languages such as English, Spanish, and French, and coding capabilities like Python, Java, and C++\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: generate_pddl, Argument: multilingual and coding-capable request for a free user, comment: route a free user request that supports multiple languages such as English, Spanish, and French, and coding capabilities like Python, Java, and C++\n",
            ">>> Observation: Tool generate_pddl failed with error: run_pipeline_for_pddl_files_generation() missing 1 required positional argument: 'comment'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: I'm still not getting it right. Let me try to provide the comment in a different format.\n",
            "\n",
            "Action: generate_pddl: multilingual and coding-capable request for a free user, {\"comment\": \"route a free user request that supports multiple languages such as English, Spanish, and French, and coding capabilities like Python, Java, and C++\"}\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: generate_pddl, Argument: multilingual and coding-capable request for a free user, {\"comment\": \"route a free user request that supports multiple languages such as English, Spanish, and French, and coding capabilities like Python, Java, and C++\"}\n",
            ">>> Observation: Tool generate_pddl failed with error: run_pipeline_for_pddl_files_generation() missing 1 required positional argument: 'comment'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: I think I need to re-examine the tool's documentation to understand how to properly provide the comment argument.\n",
            "\n",
            "Action: generate_pddl: route a free user request that supports multiple languages such as English, Spanish, and French, and coding capabilities like Python, Java, and C++\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: generate_pddl, Argument: route a free user request that supports multiple languages such as English, Spanish, and French, and coding capabilities like Python, Java, and C++\n",
            ">>> Observation: Tool generate_pddl failed with error: run_pipeline_for_pddl_files_generation() missing 1 required positional argument: 'comment'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: I'm still having trouble with the generate_pddl tool. I'll try to break it down into smaller parts and see if that helps.\n",
            "\n",
            "Action: generate_pddl: route a free user request\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: generate_pddl, Argument: route a free user request\n",
            ">>> Observation: Tool generate_pddl failed with error: run_pipeline_for_pddl_files_generation() missing 1 required positional argument: 'comment'\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: It seems like the generate_pddl function is not working as expected. I'll try to move on to the solve_pddl tool and see if that works.\n",
            "\n",
            "Action: solve_pddl:\n",
            "\n",
            "PAUSE\n",
            "--------------------------------\n",
            "Action: solve_pddl, Argument: \n",
            "Using to Pyperplan solver\n",
            "\u001b[96m  *** Credits ***\n",
            "\u001b[0m\u001b[96m  * In operation mode `OneshotPlanner` at line 9 of `<ipython-input-4-9680c8bb7370>`, \u001b[0m\u001b[96myou are using the following planning engine:\n",
            "\u001b[0m\u001b[96m  * Engine name: pyperplan\n",
            "  * Developers:  Albert-Ludwigs-Universität Freiburg (Yusra Alkhazraji, Matthias Frorath, Markus Grützner, Malte Helmert, Thomas Liebetraut, Robert Mattmüller, Manuela Ortlieb, Jendrik Seipp, Tobias Springenberg, Philip Stahl, Jan Wülfing)\n",
            "\u001b[0m\u001b[96m  * Description: \u001b[0m\u001b[96mPyperplan is a lightweight STRIPS planner written in Python.\u001b[0m\u001b[96m\n",
            "\u001b[0m\u001b[96m\n",
            "\u001b[0mPlanner used: Pyperplan\n",
            "Result Status: PlanGenerationResultStatus.SOLVED_SATISFICING\n",
            "Plan Found:\n",
            ">>> Observation: Solved PDDL. The plan is:\n",
            "route-request(req2, deepseek_deepseek_prover_v2_free)\n",
            "route-request(req1, qwen_qwen3_1_7b_free)\n",
            "\n",
            "-------- MODEL RESPONSE --------\n",
            "Thought: It looks like the solve_pddl tool was able to successfully route the request.\n",
            "\n",
            "Answer: The request was routed successfully using the plan: route-request(req2, deepseek_deepseek_prover_v2_free) route-request(req1, qwen_qwen3_1_7b_free)\n",
            "--------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thought: It looks like the solve_pddl tool was able to successfully route the request.\\n\\nAnswer: The request was routed successfully using the plan: route-request(req2, deepseek_deepseek_prover_v2_free) route-request(req1, qwen_qwen3_1_7b_free)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReAct Agent Explanation:\n",
        "\n",
        "The provided Python code implements a ReAct agent, an AI model that solves problems by thinking step-by-step and performing actions. It processes user queries by first generating a response (a \"Thought\"), then deciding if it needs to execute a tool (an \"Action\"), pausing to wait for the result, and finally using the observation from that tool to continue its reasoning. The agent repeats this process until it provides a final answer, leveraging external tools like PDDL file generation and solving planners to achieve complex tasks dynamically.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "41rEA0ed7jKr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}